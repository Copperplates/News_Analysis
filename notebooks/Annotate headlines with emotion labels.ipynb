{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from outletsBiasRatings import outletsBiasRatingsAllSides,outletAbbreviationToFullName\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
      "47\n",
      "['alternet', 'democracynow', 'db', 'hp', 'theintercept', 'jacobin', 'motherjones', 'thenewyorker', 'thenation', 'slate', 'vox', 'cnn', 'nyt', 'abcnews', 'theatlantic', 'buzzfeed', 'cbs', 'economist', 'guardian', 'nbcnews', 'politico', 'timemagazine', 'wp', 'npr', 'ap', 'bbc', 'bloomberg', 'csm', 'reuters', 'thehill', 'usatoday', 'wsj', 'reason', 'we', 'wt', 'fox', 'americanspectator', 'bre', 'theblaze', 'cbn', 'dailycaller', 'dailymail', 'dailywire', 'thefederalist', 'nationalreview', 'nyp', 'newsmax']\n"
     ]
    }
   ],
   "source": [
    "outletsBiasRatings = outletsBiasRatingsAllSides\n",
    "outlets = list(outletsBiasRatings.keys())\n",
    "startYear = 2000\n",
    "endYear = 2019\n",
    "years=[str(year) for year in range(startYear,endYear+1)]\n",
    "USE_GPU=1\n",
    "BATCH_SIZE=64\n",
    "HEADLINE_MAX_LENGTH=32\n",
    "print(years)\n",
    "print(len(outlets))\n",
    "print(outlets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# j-hartmann/emotion-english-distilroberta-base\n",
    "# https://huggingface.co/j-hartmann/emotion-english-distilroberta-base?text=Oh+wow.+I+didn%27t+know+that.\n",
    "\n",
    "## Download model for the first time\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "# model = AutoModelWithLMHead.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "\n",
    "## Save model to local folder\n",
    "# model.save_pretrained(\"./j-hartmann/emotion-english-distilroberta-base\")\n",
    "# tokenizer.save_pretrained(\"./j-hartmann/emotion-english-distilroberta-base\")\n",
    "\n",
    "# Loading model\n",
    "sentimentPipeline = pipeline(task='sentiment-analysis',model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "                             device=0)#gpu\n",
    "sentimentPipeline.save_pretrained('./j-hartmann/emotion-english-distilroberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'joy', 'score': 0.9540702104568481}]\n"
     ]
    }
   ],
   "source": [
    "predictions=sentimentPipeline(\"I'm so excited about the news\")\n",
    "print( predictions )\n",
    "def get_emotion(batch,USE_GPU):\n",
    "    try:\n",
    "        predictions=sentimentPipeline(batch)\n",
    "        predictionsEmotions=[]\n",
    "        for prediction in predictions:\n",
    "            predictionsEmotions.append(prediction['label'])\n",
    "        return predictionsEmotions\n",
    "    except Exception as e:\n",
    "        raise\n",
    "        print(e)  \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotateEmotionsInOutletHeadlines(outlet,startYear,endYear):\n",
    "    print(outlet,end=',')\n",
    "    inputPath=f'.\\headlinesData\\{outlet}'\n",
    "    outputPath=f'.\\headlinesDataWithEmotionLabelsAnnotationsFromDistilRoberta\\{outlet}'\n",
    "    if not os.path.exists(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    files=os.listdir(inputPath)\n",
    "    for file in files:\n",
    "        year=file.split('.')[0]\n",
    "        headlinesAll=[]\n",
    "        urlsAll=[]\n",
    "        emotionsLabelsAll=[]\n",
    "        if startYear <= int(year) <= endYear:\n",
    "            print(year,end=',')\n",
    "            inputFilePath=os.path.join(inputPath,file)\n",
    "            df=pd.read_csv(inputFilePath)\n",
    "#             for rowIndex, row in list(df.iterrows())[:25]:\n",
    "            for rowIndex in range(0,len(df),BATCH_SIZE):\n",
    "                try:\n",
    "                    dfBatch=df[rowIndex:rowIndex+BATCH_SIZE]\n",
    "                    headlinesBatch=list(dfBatch['title'].values)\n",
    "                    urlsBatch=list(dfBatch['url'].values)\n",
    "                    headlinesToUrlsDict={}\n",
    "                    for headlineIndex, headline in enumerate(headlinesBatch):\n",
    "                        headlinesToUrlsDict[headline]=urlsBatch[headlineIndex]\n",
    "                        \n",
    "                    headlinesBatchFiltered = [headline for headline in headlinesBatch if (type(headline)==str and len(headline.split())<=HEADLINE_MAX_LENGTH)]\n",
    "                    urlsBatchFiltered=[headlinesToUrlsDict[headline] for headline in headlinesBatchFiltered]\n",
    "                    emotionsLabelsBatchFiltered=get_emotion(headlinesBatchFiltered,USE_GPU=USE_GPU)\n",
    "                    \n",
    "                    headlinesAll += headlinesBatchFiltered \n",
    "                    urlsAll += urlsBatchFiltered \n",
    "                    emotionsLabelsAll += emotionsLabelsBatchFiltered\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(\"Something happened in sentence labeling loop\", e)\n",
    "                    continue\n",
    "            dfOut = pd.DataFrame(list(zip(emotionsLabelsAll,headlinesAll,urlsAll)), columns =['emotion', 'headline','url']) \n",
    "            outputFilePath=os.path.join(outputPath,year+'.csv')\n",
    "            dfOut.to_csv(outputFilePath,index=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alternet,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "democracynow,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "db,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "hp,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "theintercept,2014,2015,2016,2017,2018,2019,\n",
      "jacobin,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "motherjones,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "thenewyorker,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "thenation,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "slate,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "vox,2014,2015,2016,2017,2018,2019,\n",
      "cnn,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "nyt,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "abcnews,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "theatlantic,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "buzzfeed,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "cbs,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "economist,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "guardian,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "nbcnews,2014,2015,2016,2017,2018,2019,\n",
      "politico,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "timemagazine,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "wp,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "npr,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "ap,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "bbc,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "bloomberg,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "csm,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "reuters,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "thehill,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "usatoday,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "wsj,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "reason,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "we,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "wt,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "fox,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "americanspectator,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "bre,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "theblaze,2015,2016,2017,2018,2019,\n",
      "cbn,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "dailycaller,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "dailymail,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "dailywire,2015,2016,2017,2018,2019,\n",
      "thefederalist,2013,2014,2015,2016,2017,2018,2019,\n",
      "nationalreview,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "nyp,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n",
      "newsmax,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,\n"
     ]
    }
   ],
   "source": [
    "outlets = list(outletsBiasRatings.keys())\n",
    "startYear = 2000\n",
    "endYear = 2019\n",
    "\n",
    "for outlet in outlets:\n",
    "    annotateEmotionsInOutletHeadlines(outlet,startYear,endYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
